{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dog dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "#Using the load_files function from the scikit-learn library to\n",
    "#populate the following variables\n",
    "#train, valid and test_files are numpy arrays containing file paths to images\n",
    "#train, valid and test_targets are numpy arrays containing onehot-encoded labels\n",
    "#dog_names is a list os strings containing the dog breed names\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133) #133 breeds\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob('dogImages/train/*/'))]\n",
    "\n",
    "#print some statistics\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the humans dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "human_files = np.array(glob('lfw/*/*'))\n",
    "random.shuffle(human_files)\n",
    "\n",
    "#print some statistics\n",
    "print('There are %d total human images.' % len(human_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Human detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face detection with opencv Haar feature-based cascade  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#load the classifier into a variable\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "#Given an image path this function whil return true if a face was\n",
    "#detected in the image and false otherwise\n",
    "def HaarCascade_faceDetector(img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = face_cascade.detectMultiScale(gray_img)\n",
    "        return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face detection with opencv deep learning approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's time to test the two approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing in the first 100 images of humans and dogs\n",
      "98 human faces were detected in the first 100 images of humans\n",
      "10 human faces were detected in the first 100 images of dogs\n"
     ]
    }
   ],
   "source": [
    "human_files_short = human_files[:100]\n",
    "dog_files_short = train_files[:100]\n",
    "\n",
    "count_humans = 0\n",
    "count_dogs = 0\n",
    "\n",
    "for path in human_files_short:\n",
    "    if(HaarCascade_faceDetector(path)):\n",
    "        count_humans += 1\n",
    "\n",
    "for path in dog_files_short:\n",
    "    if(HaarCascade_faceDetector(path)):\n",
    "        count_dogs += 1\n",
    "\n",
    "print('Testing in the first 100 images of humans and dogs')\n",
    "print('%d human faces were detected in the first 100 images of humans' % count_humans)\n",
    "print('%d human faces were detected in the first 100 images of dogs' % count_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Detecting dogs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ResNet50 trained in the ImageNet dataset to detect if there is a dog in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "ResNet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "#Keras CNNs require a 4D tensor as input in the form\n",
    "#      (nb_samples, rows, columns, channels)\n",
    "#So we use the path_to_tensor function to convert the image into (1, 224, 224, 3)\n",
    "#And the paths_to_tensor function to make all tensors together (nb_samples, 224, 224, 3)\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    #read and resize the image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convert image to a 3D tensor with shape (224, 224, 3)\n",
    "    tensor_3d = image.img_to_array(img)\n",
    "    #convert the 3D tensor to a 4D tensor with shape (1, 224, 224, 3)\n",
    "    return np.expand_dims(tensor_3d, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "#Getting the 4D tensor ready to the ResNet50 requires some additional processing\n",
    "#like converting the RGB image to BGR and some normalization steps that\n",
    "#the preprecess function from keras will make for us\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))\n",
    "\n",
    "#now we can create the dog detector function\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing the dog detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs found in Human dataset: 1\n",
      "dogs found in dogs dataset: 100\n"
     ]
    }
   ],
   "source": [
    "count_humans = 0\n",
    "count_dogs = 0\n",
    "\n",
    "for path in human_files_short:\n",
    "    if(dog_detector(path)):\n",
    "        count_humans += 1\n",
    "\n",
    "for path in dog_files_short:\n",
    "    if(dog_detector(path)):\n",
    "        count_dogs += 1\n",
    "\n",
    "print('dogs found in Human dataset:', count_humans)\n",
    "print('dogs found in dogs dataset:', count_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNNs to classify Dog Breeds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a CNN from scratch in Keras "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
